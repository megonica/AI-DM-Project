{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7401, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I bought this belt for my daughter in-law for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The size was perfect and so was the color.  It...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fits and feels good, esp. for doing a swim rac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>These socks are absolutely the best. I take pi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thank you so much for the speedy delivery they...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiments\n",
       "0  I bought this belt for my daughter in-law for ...           1\n",
       "1  The size was perfect and so was the color.  It...           1\n",
       "2  Fits and feels good, esp. for doing a swim rac...           1\n",
       "3  These socks are absolutely the best. I take pi...           1\n",
       "4  Thank you so much for the speedy delivery they...           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('train.json')\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6319\n",
       "0    1082\n",
       "Name: sentiments, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['sentiments'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean reviews\n",
    "# Normalization - lower cased, remove stopwords, punctuations, special chars, numbers \n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "train_df['cleaned_reviews'] = train_df['reviews'].str.lower().apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)])).apply(remove_punctuations).map(lambda x: re.sub(r'\\W+\\d+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['cleaned_reviews'].to_csv('cleaned_reviews', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "# ps = PorterStemmer()\n",
    "# def stem_words(text):\n",
    "#     return ' '.join([ps.stem(word) for word in text.split()])\n",
    "# train_df['stemmed_reviews'] = train_df['cleaned_reviews'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatizer - eg. loved => love, loving => love, lovely => love\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_review(text_review):\n",
    "    empty = []\n",
    "    #loop for every tokenized word & associated tag in list\n",
    "    for word, tag in pos_tag(word_tokenize(text_review)):\n",
    "        #get first letter of tag in lower-case\n",
    "        word_tag = tag[0].lower()\n",
    "        word_tag = word_tag if word_tag in ['a', 'r', 'n', 'v'] else None\n",
    "        if not word_tag:\n",
    "            empty.append(word)\n",
    "        else:\n",
    "            # lemmatize word if word is an adjective(a), adverb(r), noun(n), or verb(v)\n",
    "            lemma = lemmatizer.lemmatize(word, word_tag)\n",
    "            empty.append(lemma)\n",
    "    return ' '.join(empty)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lemmatized_reviews'] = train_df['cleaned_reviews'].apply(lemmatize_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# 80% training, 20% testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train_df['lemmatized_reviews'], train_df['sentiments'], test_size=0.20, random_state=50, stratify=train_df['sentiments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Megan\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5920, 2000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# warnings may appear as custom tokenizer is used\n",
    "# max_df=0.9 - ignore words that appear in more than 90% of the documents\n",
    "# min_df=5 - ignore words that appear in 5 or less documents, also to filter misspelled words\n",
    "# max_features=2000 - get top 2000 words by freq\n",
    "vectorizer = TfidfVectorizer(tokenizer=word_tokenize, max_df=0.9, min_df=5, max_features=2000)\n",
    "vectorizer = vectorizer.fit(X_train)\n",
    "X_train_vectorized = vectorizer.transform(X_train)\n",
    "X_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key tuning parameters: C, penalty, solver\n",
    "# C minimises model to overfit training data, inverse of regularization strength\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# how C is determined using GridSearchCV (cross-validation method)\n",
    "parameters = {'C':[0.001,0.01,0.1,1,10,100,1000]}\n",
    "log_reg_model = LogisticRegression(max_iter=50000)\n",
    "cv = GridSearchCV(log_reg_model, parameters)\n",
    "cv.fit(X_train_vectorized, Y_train)\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# A higher value of C tells the model to give more weight to the training data\n",
    "# When we increase value of C the importance of finding proper decision boundary is increased\n",
    "# and will give less importance weight values.\n",
    "# C=1 by default\n",
    "model = LogisticRegression(C=10)\n",
    "model.fit(X_train_vectorized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "model_predictions = model.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.7433591699235841\n"
     ]
    }
   ],
   "source": [
    "#A model whose predictions are 100% wrong has an AUC of 0.0\n",
    "# one whose predictions are 100% correct has an AUC of 1.0\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC score:', roc_auc_score(Y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.900742741390952\n"
     ]
    }
   ],
   "source": [
    "#accuracy = correct_predictions / total_predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy score:', accuracy_score(Y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24553587430757468"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcualate logistic loss\n",
    "from sklearn.metrics import log_loss\n",
    "log_loss(Y_test, model.predict_proba(X_test_vectorized))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "sorted_coefficient_index = model.coef_[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest coefficient ['poor' 'disappointed' 'return' 'bother' 'cheap' 'worst' 'terrible'\n",
      " 'disappoint' 'elsewhere' 'portion']\n"
     ]
    }
   ],
   "source": [
    "print(\"Smallest coefficient\", feature_names[sorted_coefficient_index[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest coefficient ['great' 'love' 'comfortable' 'perfect' 'excellent' 'happy' 'easy' 'best'\n",
      " 'soft' 'pleased']\n"
     ]
    }
   ],
   "source": [
    "print(\"Largest coefficient\", feature_names[sorted_coefficient_index[:-11:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851, 1)\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_json('test.json')\n",
    "test_df.head()\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1851, 2000)\n"
     ]
    }
   ],
   "source": [
    "X_test = vectorizer.transform(test_df['reviews'])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "     \"Review\": list(test_df['reviews']),\n",
    "     \"Sentiments\":list(predictions),\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .str.replace('[{}]'.format(string.punctuation), '', regex=True)\n",
    "#train_df['tokenized_reviews'].to_csv('tokenized_reviews', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce6d76fd60b38149ff3543863f4529d309755f9c72712df033ff3dfb5e1287de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
